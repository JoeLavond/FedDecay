{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import packages and processed run metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'dataset', 'method', 'finetune', 'n_epochs', 'lr_', 'lr',\n",
      "       'beta', 'lr_finetune', 'regular_weight', 'K_finetune', 'K_',\n",
      "       'regular_weight_finetune', 'regular_weight_', 'Results/test_acc',\n",
      "       'Results/test_acc_bottom_decile', 'Results/test_acc_std',\n",
      "       'Results/test_f1', 'Results/test_f1_bottom_decile',\n",
      "       'Results/test_f1_std', 'Results/test_loss',\n",
      "       'Results/test_loss_bottom_decile', 'Results/test_loss_std',\n",
      "       'Results/val_acc', 'Results_unseen/test_acc',\n",
      "       'Results_unseen/test_acc.1', 'Results_unseen/test_acc.2',\n",
      "       'Results_unseen/test_acc.3', 'Results_unseen/test_f1',\n",
      "       'Results_unseen/test_f1.1', 'Results_unseen/test_f1.2',\n",
      "       'Results_unseen/test_f1.3', 'Results_unseen/test_loss',\n",
      "       'Results_unseen/test_loss.1', 'Results_unseen/test_loss.2',\n",
      "       'Results_unseen/test_loss.3', 'Results_weighted/test_acc',\n",
      "       'Results_weighted/test_f1', 'Results_weighted/test_loss',\n",
      "       'Results_weighted_unseen/test_acc', 'Results_weighted_unseen/test_f1',\n",
      "       'Results_weighted_unseen/test_loss'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# control\n",
    "project_names = ['decay--pubmed']\n",
    "validation_metric = 'Results/val_acc'\n",
    "\n",
    "# read each data set\n",
    "df = []\n",
    "for project_name in project_names:\n",
    "    temp = pd.read_csv(f'{project_name}.csv')\n",
    "    print(temp.columns)\n",
    "    df.append(temp)\n",
    "\n",
    "df = pd.concat(df, axis=0, ignore_index=True)\n",
    "#print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write function to return summaries of run's metric performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def process_run_metrics(df, method='exact'):\n",
    "    pass\n",
    "\n",
    "    # get best runs for each group\n",
    "    idx = df.groupby(['dataset', 'method', 'finetune']) \\\n",
    "        [validation_metric].idxmax()  # return index of max validation metric\n",
    "    filtered_df = df.loc[idx]\n",
    "\n",
    "\n",
    "    ## Process metrics and get top runs for each\n",
    "    # are large or small metric values are desirable?\n",
    "    descending_metrics = [name for name in filtered_df.columns if re.search('Results.*test', name)]\n",
    "    ascending_metrics = [\n",
    "        descending_metrics.pop(descending_metrics.index(name))\n",
    "        for name in descending_metrics\n",
    "        if re.search('std', name)\n",
    "    ]\n",
    "\n",
    "    # all non-metrics columns are used to identify the experimental run\n",
    "    filtered_runs = filtered_df[[\n",
    "        name for name in filtered_df.columns\n",
    "        if name not in descending_metrics + ascending_metrics\n",
    "    ]]\n",
    "\n",
    "    # rank the metrics\n",
    "    ranked_descending = filtered_df[descending_metrics].rank(\n",
    "        method='first',\n",
    "        ascending=False\n",
    "    )\n",
    "    ranked_ascending = filtered_df[ascending_metrics].rank(\n",
    "        method='first',\n",
    "        ascending=True\n",
    "    )\n",
    "\n",
    "    # combine and sort the ranked_metrics\n",
    "    ranked_metrics = pd.concat([ranked_descending, ranked_ascending], axis=1)\n",
    "    ranked_metrics = ranked_metrics[sorted(ranked_metrics.columns)]\n",
    "    filtered_ranks = filtered_runs.join(ranked_metrics)\n",
    "\n",
    "\n",
    "    ## Manipulate rank data to be summarized by runs and metrics\n",
    "    # convert to long format\n",
    "    # filter to top ranks\n",
    "    long_filtered_ranks = pd.melt(filtered_ranks, id_vars=filtered_runs.columns, var_name='metric')\n",
    "    top_filtered_metrics = long_filtered_ranks.loc[long_filtered_ranks.value <= 3].copy()  # top 3 runs\n",
    "\n",
    "    # compute rank summaries to understand what runs are top overall\n",
    "    top_filtered_metrics['rank_one_ind'] = (top_filtered_metrics.value == 1)\n",
    "    top_filtered_metrics['rank_two_ind'] = (top_filtered_metrics.value == 2)\n",
    "    top_filtered_metrics['rank_three_ind'] = (top_filtered_metrics.value == 3)\n",
    "    top_filtered_metrics.replace(False, pd.NA, inplace=True)\n",
    "\n",
    "    # summarized metric ranks for run type\n",
    "    rank_summary_columns = ['rank_one_ind', 'rank_two_ind', 'rank_three_ind', 'value']\n",
    "    id_columns = ['dataset', 'method', 'finetune']\n",
    "    run_summary = top_filtered_metrics.groupby(id_columns)[rank_summary_columns].count()\n",
    "\n",
    "    # summarize metric ranks for metric choice\n",
    "    metric_summary = top_filtered_metrics.loc[top_filtered_metrics.method == method]\n",
    "    metric_summary = metric_summary.sort_values(by='metric').groupby('metric')[rank_summary_columns].count()\n",
    "\n",
    "    return (\n",
    "        metric_summary,\n",
    "        run_summary,\n",
    "        filtered_runs\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter data to runs of interest\n",
    "Apply summary function to filtered dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joela\\AppData\\Local\\Temp\\ipykernel_27484\\1571230217.py:26: FutureWarning: Dropping of nuisance columns in DataFrame.rank is deprecated; in a future version this will raise TypeError. Select only valid columns before calling rank.\n",
      "  ranked_descending = filtered_df[descending_metrics].rank(\n"
     ]
    }
   ],
   "source": [
    "subset_df = df\n",
    "subset_df = subset_df.loc[(df.n_epochs < 6)]\n",
    "#subset_df = subset_df.loc[(df.beta * 10 % 2 == 0) | (df.method != 'exact')]\n",
    "(my_metric_summary, my_run_summary, _) = process_run_metrics(subset_df, method='exact')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "View processed summaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                        rank_one_ind  rank_two_ind  \\\nmetric                                                               \nResults_unseen/test_acc_std                        0             1   \nResults_unseen/test_loss_bottom_decile             0             1   \nResults_unseen/test_loss_std                       0             1   \nResults/test_f1                                    0             0   \nResults_unseen/test_acc_bottom_decile              0             0   \nResults_unseen/test_f1_std                         0             0   \nResults_weighted/test_f1                           0             0   \n\n                                        rank_three_ind  value  \nmetric                                                         \nResults_unseen/test_acc_std                          0      1  \nResults_unseen/test_loss_bottom_decile               0      1  \nResults_unseen/test_loss_std                         0      1  \nResults/test_f1                                      1      1  \nResults_unseen/test_acc_bottom_decile                1      1  \nResults_unseen/test_f1_std                           1      1  \nResults_weighted/test_f1                             1      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank_one_ind</th>\n      <th>rank_two_ind</th>\n      <th>rank_three_ind</th>\n      <th>value</th>\n    </tr>\n    <tr>\n      <th>metric</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Results_unseen/test_acc_std</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Results_unseen/test_loss_bottom_decile</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Results_unseen/test_loss_std</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Results/test_f1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Results_unseen/test_acc_bottom_decile</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Results_unseen/test_f1_std</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Results_weighted/test_f1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(my_metric_summary.shape)\n",
    "sort_by = ['value', 'rank_one_ind', 'rank_two_ind', 'rank_three_ind']\n",
    "my_metric_summary.sort_values(by=sort_by, ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                         rank_one_ind  rank_two_ind  rank_three_ind  value\ndataset method finetune                                                   \npubmed  fedbn  1                    7             1               2     10\n        ditto  1                    1             3               5      9\n        fedavg 1                    1             4               4      9\n        pfedme 1                    1             4               3      8\nsst2    pfedme 0                    3             0               2      5\n        exact  0                    0             3               2      5\npubmed  fedbn  0                    2             3               0      5\nsst2    ditto  0                    4             0               0      4\npubmed  ditto  0                    3             0               1      4\n        fedavg 0                    1             3               0      4\n        fedem  1                    2             1               0      3\n               0                    1             0               2      3\nsst2    ditto  1                    0             2               0      2\n        fedbn  0                    0             0               2      2\n        fedem  0                    0             1               1      2\npubmed  exact  1                    0             0               2      2\nsst2    pfedme 1                    0             2               0      2\n        fedavg 0                    0             0               1      1\n        fedbn  1                    1             0               0      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>rank_one_ind</th>\n      <th>rank_two_ind</th>\n      <th>rank_three_ind</th>\n      <th>value</th>\n    </tr>\n    <tr>\n      <th>dataset</th>\n      <th>method</th>\n      <th>finetune</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">pubmed</th>\n      <th>fedbn</th>\n      <th>1</th>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>ditto</th>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>fedavg</th>\n      <th>1</th>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>pfedme</th>\n      <th>1</th>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">sst2</th>\n      <th>pfedme</th>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>exact</th>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>pubmed</th>\n      <th>fedbn</th>\n      <th>0</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>sst2</th>\n      <th>ditto</th>\n      <th>0</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">pubmed</th>\n      <th>ditto</th>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>fedavg</th>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">fedem</th>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">sst2</th>\n      <th>ditto</th>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>fedbn</th>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>fedem</th>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>pubmed</th>\n      <th>exact</th>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">sst2</th>\n      <th>pfedme</th>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>fedavg</th>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>fedbn</th>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(my_run_summary.shape)\n",
    "my_run_summary.sort_values(by='value', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
