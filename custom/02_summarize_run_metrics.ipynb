{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import packages and processed run metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.218159Z",
     "end_time": "2023-04-20T14:56:30.337018Z"
    }
   },
   "outputs": [],
   "source": [
    "# packages\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# source\n",
    "helper = __import__('00_helper')\n",
    "\n",
    "# control\n",
    "write_files = 1\n",
    "validation_metric = 'Results/val_acc'\n",
    "project_names = [\n",
    "    'femnist--s02', 'sst2', 'pubmed'#,\n",
    "    #'cifar--alpha5.0', 'cifar--alpha0.5', 'cifar--alpha0.1'\n",
    "]\n",
    "df = helper.load_data(project_names)\n",
    "\n",
    "## For CIFAR\n",
    "# remove_methods = [\n",
    "#     method for method in df.method.unique()\n",
    "#     if method not in ['fedavg', 'exact']\n",
    "# ]\n",
    "\n",
    "# Custom sorts\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cat_method_type = CategoricalDtype(\n",
    "    [\n",
    "        'ditto', 'fedbn', 'fedem', 'pfedme',  # pfl-methods\n",
    "        'fomaml', 'fedavg', 'exact'  # ml-methodsd\n",
    "    ],\n",
    "    ordered=True\n",
    ")\n",
    "cat_dataset_type = CategoricalDtype(\n",
    "    ['femnist--s02', 'sst2', 'pubmed'],\n",
    "    ordered=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def df_to_latex(\n",
    "    df,\n",
    "    id_columns,\n",
    "    file_name=None,\n",
    "    remove_columns=None,\n",
    "    file_path='output'\n",
    "):\n",
    "\n",
    "    # remove columns not of interest\n",
    "    if remove_columns is None:\n",
    "        remove_columns = list()\n",
    "    temp_df = df[[name for name in df.columns if name not in remove_columns]]\n",
    "\n",
    "    # sort by id columns\n",
    "    temp_df = temp_df.sort_values(by=id_columns)\n",
    "\n",
    "    # create output file\n",
    "    string_df = temp_df.to_string(\n",
    "        header=True,\n",
    "        index=False,\n",
    "        index_names=False\n",
    "    )\n",
    "\n",
    "    # remove any leading space\n",
    "    string_df = re.sub('^[\\s]+', '', string_df)\n",
    "    # remove leading space after newlines\n",
    "    string_df = re.sub('\\n[\\s]+', '\\n', string_df)\n",
    "    # replace white space between words with table column skip\n",
    "    string_df = re.sub('[ \\t]+', ' & ', string_df)\n",
    "\n",
    "    # add latex newline to end of each line\n",
    "    string_df = string_df.replace('_', ' ')\n",
    "    string_df = string_df.replace('\\n', ' \\\\\\\\\\n')\n",
    "    string_df = string_df + ' \\\\\\\\'\n",
    "\n",
    "    if file_name is not None:\n",
    "\n",
    "        # write to file\n",
    "        with open(os.path.join(file_path, f'{file_name}.txt'), 'w') as f:\n",
    "            f.writelines(string_df)\n",
    "\n",
    "    else:\n",
    "        return string_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.211179Z",
     "end_time": "2023-04-20T14:56:30.337018Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter data to runs of interest\n",
    "Apply summary function to filtered dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subset_df = df\n",
    "print('input dataset:', df.shape)\n",
    "\n",
    "## row (run) filtering\n",
    "# remove extra hyper-parameter searches\n",
    "\n",
    "subset_df = subset_df.loc[(subset_df.n_epochs < 6)]\n",
    "print('\\t reduce to 3 or fewer local update steps:', subset_df.shape)\n",
    "\n",
    "subset_df = subset_df.loc[(subset_df.K < 6) | (subset_df.method != 'pfedme')]\n",
    "print('\\t reduce to 3 or fewer local meta-learning steps for pfedme:', subset_df.shape)\n",
    "\n",
    "subset_df = subset_df.loc[((10 * subset_df.beta).astype('Int64') % 2 == 0) | (subset_df.method != 'exact')]\n",
    "print('\\t reduce beta grid for decay:', subset_df.shape)\n",
    "\n",
    "## column (metric) filtering\n",
    "subset_df = subset_df[[\n",
    "    name for name in subset_df.columns\n",
    "    if (\n",
    "        not re.search('^sys', name)\n",
    "        and not re.search('f1', name)\n",
    "        and not re.search('loss', name)\n",
    "    )\n",
    "]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.217163Z",
     "end_time": "2023-04-20T14:56:30.338215Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## get best runs for each group\n",
    "# regardless of finetuning\n",
    "best_runs = subset_df.loc[\n",
    "    subset_df.groupby(['dataset', 'method', 'finetune']) \\\n",
    "    [validation_metric].idxmax()  # return index of max validation metric\n",
    "]\n",
    "best_runs['method'] = best_runs['method'].astype(cat_method_type)\n",
    "best_runs['dataset'] = best_runs['dataset'].astype(cat_dataset_type)\n",
    "\n",
    "# treat finetuning groups as seperate\n",
    "ft_yes = best_runs.loc[best_runs.finetune == 1]\n",
    "ft_no = best_runs.loc[best_runs.finetune == 0]\n",
    "\n",
    "# best_runs.loc[[method not in remove_methods for method in best_runs.method]].head(12)\n",
    "best_runs.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.217163Z",
     "end_time": "2023-04-20T14:56:30.350469Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For all best runs, regardless of finetuning, produce summaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For existing users, FT since sufficient data\n",
    "seen_best_runs = ft_yes[[\n",
    "    name for name in ft_yes.columns\n",
    "    if (\n",
    "        not re.search('weighted', name)\n",
    "        and not re.search('unseen', name)\n",
    "    )\n",
    "    or (\n",
    "        not re.search('Results', name)\n",
    "        or re.search('val', name)\n",
    "    )\n",
    "]]\n",
    "\n",
    "if write_files:\n",
    "    helper.runs_to_latex(seen_best_runs, 'seen--ft_yes')\n",
    "\n",
    "(seen_run_summary, seen_metric_summary, seen_rank_summary) = helper.process_run_metrics(seen_best_runs)\n",
    "print('all runs:', seen_run_summary.shape)\n",
    "print('all metrics:', seen_metric_summary.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.223145Z",
     "end_time": "2023-04-20T14:56:30.410941Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run summary\n",
    "seen_run_summary.sort_values(by='value', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.223145Z",
     "end_time": "2023-04-20T14:56:30.426487Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "View processed summaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# metrics summary\n",
    "sort_by = ['value', 'rank_one_ind', 'rank_two_ind', 'rank_three_ind']\n",
    "seen_metric_summary.sort_values(by=sort_by, ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.228132Z",
     "end_time": "2023-04-20T14:56:30.450477Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now seperately, based on finetuning status, repeat the above summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unseen_best_runs = best_runs[[\n",
    "    name for name in ft_yes.columns\n",
    "    if (\n",
    "               not re.search('weighted', name)\n",
    "               and re.search('unseen', name)\n",
    "       )\n",
    "       or (\n",
    "               not re.search('Results', name)\n",
    "               or re.search('val', name)\n",
    "       )\n",
    "]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.235113Z",
     "end_time": "2023-04-20T14:56:30.456406Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ft_yes = unseen_best_runs.loc[unseen_best_runs.finetune == 1]\n",
    "ft_no = unseen_best_runs.loc[unseen_best_runs.finetune == 0]\n",
    "\n",
    "(yes_run_summary, yes_metric_summary, _) = helper.process_run_metrics(ft_yes)\n",
    "if write_files:\n",
    "    helper.runs_to_latex(ft_yes, 'unseen--ft_yes')\n",
    "\n",
    "(no_run_summary, no_metric_summary, _) = helper.process_run_metrics(ft_no)\n",
    "if write_files:\n",
    "    helper.runs_to_latex(ft_no, 'unseen--ft_no')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.235113Z",
     "end_time": "2023-04-20T14:56:30.562276Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run summary\n",
    "yes_run_summary.sort_values(by='value', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.235113Z",
     "end_time": "2023-04-20T14:56:30.577240Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# metrics summary\n",
    "yes_metric_summary.sort_values(by=sort_by, ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.235113Z",
     "end_time": "2023-04-20T14:56:30.599042Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run summary\n",
    "no_run_summary.sort_values(by='value', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.235113Z",
     "end_time": "2023-04-20T14:56:30.610012Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# metrics summary\n",
    "no_metric_summary.sort_values(by=sort_by, ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.235113Z",
     "end_time": "2023-04-20T14:56:30.639932Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Temporary scratch work below"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_columns = ['method', 'finetune', 'dataset']\n",
    "metrics = ['Results/test_acc','Results_unseen/test_acc']\n",
    "temp = best_runs[id_columns + metrics]\n",
    "temp['generalization_gap'] = temp['Results_unseen/test_acc'] - temp['Results/test_acc']\n",
    "\n",
    "s = df_to_latex(temp, id_columns)\n",
    "print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T14:56:30.240100Z",
     "end_time": "2023-04-20T14:56:30.653896Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
