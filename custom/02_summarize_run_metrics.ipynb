{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import packages and processed run metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1201, 36)\n",
      "(780, 28)\n",
      "(560, 27)\n",
      "(520, 27)\n",
      "(520, 27)\n",
      "\n",
      "all runs: (3581, 37)\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# control\n",
    "project_names = [\n",
    "    'decay--sst2',\n",
    "    'decay--pubmed',\n",
    "    'decay--cifar--alpha5.0',\n",
    "    'decay--cifar--alpha0.5',\n",
    "    'decay--cifar--alpha0.1'\n",
    "]\n",
    "validation_metric = 'Results/val_acc'\n",
    "\n",
    "# read each data set\n",
    "df = []\n",
    "for project_name in project_names:\n",
    "    temp = pd.read_csv(f'{project_name}.csv')\n",
    "    print(temp.shape)\n",
    "    df.append(temp)\n",
    "\n",
    "df = pd.concat(df, axis=0, ignore_index=True)\n",
    "print()\n",
    "print('all runs:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write function to return summaries of run's metric performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def process_run_metrics(df, method='exact'):\n",
    "    pass\n",
    "\n",
    "    # get best runs for each group\n",
    "    idx = df.groupby(['dataset', 'method', 'finetune']) \\\n",
    "        [validation_metric].idxmax()  # return index of max validation metric\n",
    "    filtered_df = df.loc[idx]\n",
    "\n",
    "\n",
    "    ## Process metrics and get top runs for each\n",
    "    # are large or small metric values are desirable?\n",
    "    descending_metrics = [name for name in filtered_df.columns if re.search('Results.*test', name)]\n",
    "    ascending_metrics = [\n",
    "        descending_metrics.pop(descending_metrics.index(name))\n",
    "        for name in descending_metrics\n",
    "        if re.search('std', name)\n",
    "    ]\n",
    "    print('metrics:')\n",
    "    print('\\t', descending_metrics)\n",
    "    print('\\t', ascending_metrics)\n",
    "\n",
    "    # convert metrics to numeric\n",
    "    #filtered_df[descending_metrics + ascending_metrics] = filtered_df[descending_metrics + ascending_metrics].apply(pd.to_numeric)\n",
    "\n",
    "    # all non-metrics columns are used to identify the experimental run\n",
    "    filtered_runs = filtered_df[[\n",
    "        name for name in filtered_df.columns\n",
    "        if name not in descending_metrics + ascending_metrics\n",
    "    ]]\n",
    "\n",
    "    # rank the metrics\n",
    "    ranked_descending = filtered_df.groupby(['dataset'])[descending_metrics].rank(\n",
    "        method='min',\n",
    "        ascending=False\n",
    "    )\n",
    "    ranked_ascending = filtered_df.groupby(['dataset'])[ascending_metrics].rank(\n",
    "        method='min',\n",
    "        ascending=True\n",
    "    )\n",
    "\n",
    "    # combine and sort the ranked_metrics\n",
    "    ranked_metrics = pd.concat([ranked_descending, ranked_ascending], axis=1)\n",
    "    ranked_metrics = ranked_metrics[sorted(ranked_metrics.columns)]\n",
    "    filtered_ranks = filtered_runs.join(ranked_metrics)\n",
    "\n",
    "\n",
    "    ## Manipulate rank data to be summarized by runs and metrics\n",
    "    # convert to long format\n",
    "    # filter to top ranks\n",
    "    long_filtered_ranks = pd.melt(filtered_ranks, id_vars=filtered_runs.columns, var_name='metric')\n",
    "    top_filtered_metrics = long_filtered_ranks.loc[long_filtered_ranks.value <= 3].copy()  # top 3 runs\n",
    "\n",
    "    # compute rank summaries to understand what runs are top overall\n",
    "    top_filtered_metrics['rank_one_ind'] = (top_filtered_metrics.value == 1)\n",
    "    top_filtered_metrics['rank_two_ind'] = (top_filtered_metrics.value == 2)\n",
    "    top_filtered_metrics['rank_three_ind'] = (top_filtered_metrics.value == 3)\n",
    "    top_filtered_metrics.replace(False, pd.NA, inplace=True)\n",
    "\n",
    "    # summarized metric ranks for run type\n",
    "    rank_summary_columns = ['rank_one_ind', 'rank_two_ind', 'rank_three_ind', 'value']\n",
    "    #id_columns = ['dataset', 'method', 'finetune']\n",
    "    id_columns = ['method', 'finetune']\n",
    "    run_summary = top_filtered_metrics.groupby(id_columns)[rank_summary_columns].count()\n",
    "\n",
    "    # summarize metric ranks for metric choice\n",
    "    metric_summary = top_filtered_metrics.loc[top_filtered_metrics.method == method]\n",
    "    metric_summary = metric_summary.sort_values(by='metric').groupby('metric')[rank_summary_columns].count()\n",
    "\n",
    "    return (\n",
    "        run_summary,\n",
    "        metric_summary,\n",
    "        filtered_runs\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter data to runs of interest\n",
    "Apply summary function to filtered dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics:\n",
      "\t ['Results/test_acc', 'Results/test_acc_bottom_decile', 'Results_unseen/test_acc', 'Results_unseen/test_acc_bottom_decile', 'Results_weighted/test_acc', 'Results_weighted_unseen/test_acc']\n",
      "\t ['Results/test_acc_std', 'Results_unseen/test_acc_std']\n"
     ]
    }
   ],
   "source": [
    "subset_df = df\n",
    "\n",
    "# row (run) filtering\n",
    "subset_df = subset_df.loc[(df.n_epochs < 6)]\n",
    "betas = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "subset_df = subset_df.loc[[\n",
    "    True if beta in betas else False\n",
    "    for beta in subset_df.beta\n",
    "    ] | (subset_df.method != 'exact')\n",
    "]\n",
    "\n",
    "# column (metric) filtering\n",
    "subset_df = subset_df[[\n",
    "    name for name in subset_df.columns\n",
    "    if not re.search('f1', name)\n",
    "       and not re.search('loss', name)\n",
    "]]\n",
    "\n",
    "(my_run_summary, my_metric_summary, temp) = process_run_metrics(subset_df, method='exact')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "View processed summaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 rank_one_ind  rank_two_ind  rank_three_ind  value\nmethod finetune                                                   \nexact  0                   14             8               4     26\nfedavg 0                   11             9               3     23\nfedem  0                    6             4              13     23\npfedme 0                    8             3               3     14\nexact  1                    4             3               0      7\nfedbn  1                    1             3               3      7\nfedem  1                    2             1               2      5\npfedme 1                    2             0               2      4\nfedavg 1                    0             1               1      2\nfedbn  0                    0             2               0      2\nditto  0                    1             0               0      1\n       1                    0             1               0      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>rank_one_ind</th>\n      <th>rank_two_ind</th>\n      <th>rank_three_ind</th>\n      <th>value</th>\n    </tr>\n    <tr>\n      <th>method</th>\n      <th>finetune</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>exact</th>\n      <th>0</th>\n      <td>14</td>\n      <td>8</td>\n      <td>4</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>fedavg</th>\n      <th>0</th>\n      <td>11</td>\n      <td>9</td>\n      <td>3</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>fedem</th>\n      <th>0</th>\n      <td>6</td>\n      <td>4</td>\n      <td>13</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>pfedme</th>\n      <th>0</th>\n      <td>8</td>\n      <td>3</td>\n      <td>3</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>exact</th>\n      <th>1</th>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>fedbn</th>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>fedem</th>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>pfedme</th>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>fedavg</th>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>fedbn</th>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">ditto</th>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(my_run_summary.shape)\n",
    "my_run_summary.sort_values(by='value', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                       rank_one_ind  rank_two_ind  \\\nmetric                                                              \nResults_unseen/test_acc                           3             1   \nResults_weighted_unseen/test_acc                  3             1   \nResults/test_acc_bottom_decile                    2             3   \nResults/test_acc_std                              4             0   \nResults/test_acc                                  2             2   \nResults_unseen/test_acc_std                       1             2   \nResults_unseen/test_acc_bottom_decile             2             0   \nResults_weighted/test_acc                         1             2   \n\n                                       rank_three_ind  value  \nmetric                                                        \nResults_unseen/test_acc                             1      5  \nResults_weighted_unseen/test_acc                    1      5  \nResults/test_acc_bottom_decile                      0      5  \nResults/test_acc_std                                0      4  \nResults/test_acc                                    0      4  \nResults_unseen/test_acc_std                         1      4  \nResults_unseen/test_acc_bottom_decile               1      3  \nResults_weighted/test_acc                           0      3  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank_one_ind</th>\n      <th>rank_two_ind</th>\n      <th>rank_three_ind</th>\n      <th>value</th>\n    </tr>\n    <tr>\n      <th>metric</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Results_unseen/test_acc</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Results_weighted_unseen/test_acc</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Results/test_acc_bottom_decile</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Results/test_acc_std</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Results/test_acc</th>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Results_unseen/test_acc_std</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Results_unseen/test_acc_bottom_decile</th>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>Results_weighted/test_acc</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(my_metric_summary.shape)\n",
    "sort_by = ['value', 'rank_one_ind', 'rank_two_ind', 'rank_three_ind']\n",
    "my_metric_summary.sort_values(by=sort_by, ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0  method  finetune          dataset  n_epochs  batch_size  \\\n3399         338   ditto         0  cifar--alpha0.1         3         NaN   \n3548         487   exact         0  cifar--alpha0.1         3         NaN   \n3373         312  fedavg         0  cifar--alpha0.1         3         NaN   \n3351         290   fedbn         0  cifar--alpha0.1         3         NaN   \n3353         292   fedbn         1  cifar--alpha0.1         3         NaN   \n\n        lr  beta  regular_weight   K  finetune_lr  Results/val_acc  alpha  \n3399  0.50   NaN             0.5 NaN          NaN         0.487736    0.1  \n3548  0.10   0.2             NaN NaN          NaN         0.566214    0.1  \n3373  0.05   NaN             NaN NaN          NaN         0.553132    0.1  \n3351  0.10   NaN             NaN NaN          NaN         0.407272    0.1  \n3353  0.01   NaN             NaN NaN          NaN         0.349454    0.1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>method</th>\n      <th>finetune</th>\n      <th>dataset</th>\n      <th>n_epochs</th>\n      <th>batch_size</th>\n      <th>lr</th>\n      <th>beta</th>\n      <th>regular_weight</th>\n      <th>K</th>\n      <th>finetune_lr</th>\n      <th>Results/val_acc</th>\n      <th>alpha</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3399</th>\n      <td>338</td>\n      <td>ditto</td>\n      <td>0</td>\n      <td>cifar--alpha0.1</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0.50</td>\n      <td>NaN</td>\n      <td>0.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.487736</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>3548</th>\n      <td>487</td>\n      <td>exact</td>\n      <td>0</td>\n      <td>cifar--alpha0.1</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0.10</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.566214</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>3373</th>\n      <td>312</td>\n      <td>fedavg</td>\n      <td>0</td>\n      <td>cifar--alpha0.1</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0.05</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.553132</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>3351</th>\n      <td>290</td>\n      <td>fedbn</td>\n      <td>0</td>\n      <td>cifar--alpha0.1</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0.10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.407272</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>3353</th>\n      <td>292</td>\n      <td>fedbn</td>\n      <td>1</td>\n      <td>cifar--alpha0.1</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0.01</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.349454</td>\n      <td>0.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
