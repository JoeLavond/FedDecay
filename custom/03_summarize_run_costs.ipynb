{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import packages and processed run metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-19T13:46:52.648132Z",
     "end_time": "2023-04-19T13:46:52.720491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input datasets:\n",
      "\t (651, 36)\n",
      "\t (1200, 44)\n",
      "\t (780, 37)\n",
      "all runs: (2631, 44)\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# source\n",
    "helper = __import__('00_helper')\n",
    "\n",
    "# control\n",
    "top_k = 1\n",
    "with_ft = 1\n",
    "write_output = 1\n",
    "\n",
    "validation_metric = 'Results/val_acc'\n",
    "project_names = [\n",
    "    'femnist--s02', 'sst2', 'pubmed'\n",
    "    #'cifar--alpha5.0', 'cifar--alpha0.5', 'cifar--alpha0.1'\n",
    "]\n",
    "\n",
    "df = helper.load_data(project_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def df_to_latex(\n",
    "    df,\n",
    "    id_columns,\n",
    "    file_name=None,\n",
    "    remove_columns=None,\n",
    "    file_path='output'\n",
    "):\n",
    "\n",
    "    # remove columns not of interest\n",
    "    if remove_columns is None:\n",
    "        remove_columns = list()\n",
    "    temp_df = df[[name for name in df.columns if name not in remove_columns]]\n",
    "\n",
    "    # sort by id columns\n",
    "    temp_df = temp_df.sort_values(by=id_columns)\n",
    "\n",
    "    # create output file\n",
    "    string_df = temp_df.to_string(\n",
    "        header=True,\n",
    "        index=False,\n",
    "        index_names=False\n",
    "    )\n",
    "\n",
    "    # remove any leading space\n",
    "    string_df = re.sub('^[\\s]+', '', string_df)\n",
    "    # remove leading space after newlines\n",
    "    string_df = re.sub('\\n[\\s]+', '\\n', string_df)\n",
    "    # replace white space between words with table column skip\n",
    "    string_df = re.sub('[ \\t]+', ' & ', string_df)\n",
    "\n",
    "    # add latex newline to end of each line\n",
    "    string_df = string_df.replace('_', ' ')\n",
    "    string_df = string_df.replace('\\n', ' \\\\\\\\\\n')\n",
    "    string_df = string_df + ' \\\\\\\\'\n",
    "\n",
    "    if file_name is not None:\n",
    "\n",
    "        # write to file\n",
    "        with open(os.path.join(file_path, f'{file_name}.txt'), 'w') as f:\n",
    "            f.writelines(string_df)\n",
    "\n",
    "    else:\n",
    "        return string_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T13:46:52.713509Z",
     "end_time": "2023-04-19T13:46:52.727476Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter data to runs of interest\n",
    "Apply summary function to filtered dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dataset: (2631, 44)\n",
      "\t reduce to 3 or fewer local update steps: (1945, 44)\n",
      "\t reduce to 3 or fewer local meta-learning steps for pfedme: (1865, 44)\n",
      "\t reduce beta grid for decay: (1768, 44)\n"
     ]
    }
   ],
   "source": [
    "subset_df = df\n",
    "print('input dataset:', df.shape)\n",
    "\n",
    "## row (run) filtering\n",
    "# remove extra hyper-parameter searches\n",
    "\n",
    "subset_df = subset_df.loc[(subset_df.n_epochs < 6)]\n",
    "print('\\t reduce to 3 or fewer local update steps:', subset_df.shape)\n",
    "\n",
    "subset_df = subset_df.loc[(subset_df.K < 6) | (subset_df.method != 'pfedme')]\n",
    "print('\\t reduce to 3 or fewer local meta-learning steps for pfedme:', subset_df.shape)\n",
    "\n",
    "subset_df = subset_df.loc[((10 * subset_df.beta).astype('Int64') % 2 == 0) | (subset_df.method != 'exact')]\n",
    "print('\\t reduce beta grid for decay:', subset_df.shape)\n",
    "\n",
    "## column (metric) filtering\n",
    "subset_df = subset_df[[\n",
    "    name for name in subset_df.columns\n",
    "    if (\n",
    "        not re.search('test', name)\n",
    "        and not re.search('f1', name)\n",
    "        and not re.search('loss', name)\n",
    "    )\n",
    "]]\n",
    "\n",
    "def convert_SI(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "\n",
    "    SI = {\n",
    "        'K': 10e3,\n",
    "        'M': 10e6,\n",
    "        'G': 10e9,\n",
    "        'T': 10e12\n",
    "    }\n",
    "\n",
    "    units = re.sub('[0-9.]', '', x)\n",
    "    x = float(re.sub('[^0-9.]', '', x))\n",
    "\n",
    "    if units == '':\n",
    "        return x\n",
    "    return x * SI[units]\n",
    "\n",
    "\n",
    "def to_SI(x, unit='G', decimals=2):\n",
    "    SI = {\n",
    "        'K': 10e3, 'M': 10e6,\n",
    "        'G': 10e9, 'T': 10e12\n",
    "    }\n",
    "\n",
    "    assert unit in [name for name, _ in SI.items()]\n",
    "    return str(round(x / SI[unit], decimals)) + f' {unit}'\n",
    "\n",
    "\n",
    "#convert_SI('19.0M')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T13:46:52.735455Z",
     "end_time": "2023-04-19T13:46:52.796042Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics: ['sys_avg/total_flops', 'sys_avg/global_convergence_time_minutes', 'sys_avg/fl_end_time_minutes', 'sys_avg/global_convergence_round', 'sys_avg/local_convergence_round', 'sys_avg/total_download_bytes', 'sys_avg/total_upload_bytes', 'sys_avg/local_convergence_time_minutes', 'sys_avg/total_model_size']\n",
      "before: (634, 13)\n",
      "after: (18, 13)\n"
     ]
    }
   ],
   "source": [
    "# columns of interest\n",
    "id_columns = ['dataset', 'method', validation_metric]\n",
    "metrics = [name for name in subset_df.columns if re.search('^sys', name)]\n",
    "print('metrics:', metrics)\n",
    "object_metrics= [\n",
    "    name for name, types in zip(subset_df.columns, subset_df.dtypes)\n",
    "    if re.search('^sys', name)\n",
    "    and types == 'object'\n",
    "]\n",
    "\n",
    "float_df = subset_df.loc[subset_df.finetune == with_ft]\n",
    "float_df = float_df[id_columns + metrics]\n",
    "float_df[object_metrics] = float_df[object_metrics].applymap(convert_SI).apply(pd.to_numeric)\n",
    "float_df['sys_avg/total_bytes'] = float_df['sys_avg/total_download_bytes'] \\\n",
    "                          + float_df['sys_avg/total_upload_bytes']\n",
    "\n",
    "# filter all non-zero\n",
    "float_df = float_df.loc[\n",
    "    (float_df['sys_avg/global_convergence_round'] > 0)\n",
    "    & (float_df['sys_avg/global_convergence_time_minutes'] > 0)\n",
    "    & (float_df['sys_avg/total_bytes'] > 0)\n",
    "    & (float_df['sys_avg/total_flops'] > 0)\n",
    "]\n",
    "\n",
    "## get best runs for each group\n",
    "print('before:', float_df.shape)\n",
    "best_runs = float_df \\\n",
    "    .sort_values(by=validation_metric, ascending=False) \\\n",
    "    .groupby(['dataset', 'method']) \\\n",
    "    .head(top_k)\n",
    "print('after:', best_runs.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T13:46:52.757978Z",
     "end_time": "2023-04-19T13:46:52.818145Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "sub_metrics = [\n",
    "    'sys_avg/global_convergence_round',\n",
    "    'sys_avg/global_convergence_time_minutes',\n",
    "    'sys_avg/total_bytes',\n",
    "    'sys_avg/total_flops'\n",
    "]\n",
    "id_columns = ['method', 'dataset']\n",
    "avg_runs = best_runs.groupby(id_columns)[sub_metrics].mean()\n",
    "\n",
    "avg_runs['sys_avg/global_convergence_round'] = avg_runs['sys_avg/global_convergence_round'].apply(round, ndigits=2)\n",
    "avg_runs['sys_avg/global_convergence_time_minutes'] = avg_runs['sys_avg/global_convergence_time_minutes'].apply(round, ndigits=2)\n",
    "avg_runs['sys_avg/total_bytes'] = avg_runs['sys_avg/total_bytes'].apply(to_SI, unit='M')\n",
    "avg_runs['sys_avg/total_flops'] = avg_runs['sys_avg/total_flops'].apply(to_SI, unit='G')\n",
    "avg_runs = avg_runs.add_suffix('_mean').reset_index()\n",
    "\n",
    "avg_runs.columns = [re.sub('sys_avg/', '', name) for name in avg_runs.columns]\n",
    "if write_output:\n",
    "    df_to_latex(avg_runs, id_columns, 'method_costs--ft_' + ('yes' if with_ft else 'no'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T13:46:52.803263Z",
     "end_time": "2023-04-19T13:46:52.903104Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "  method       dataset  global_convergence_round_mean  \\\n0  ditto  femnist--s02                          830.0   \n1  ditto        pubmed                          115.0   \n2  ditto          sst2                           45.0   \n3  exact  femnist--s02                          350.0   \n4  exact        pubmed                          135.0   \n5  exact          sst2                           60.0   \n\n   global_convergence_time_minutes_mean total_bytes_mean total_flops_mean  \n0                                188.57            3.9 M         2970.0 G  \n1                                  0.51           3.28 M           45.7 G  \n2                                137.34           0.66 M         1650.0 G  \n3                                 89.84           1.68 M         527.52 G  \n4                                  1.06           3.85 M          60.38 G  \n5                                 34.34           0.88 M         873.33 G  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>method</th>\n      <th>dataset</th>\n      <th>global_convergence_round_mean</th>\n      <th>global_convergence_time_minutes_mean</th>\n      <th>total_bytes_mean</th>\n      <th>total_flops_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ditto</td>\n      <td>femnist--s02</td>\n      <td>830.0</td>\n      <td>188.57</td>\n      <td>3.9 M</td>\n      <td>2970.0 G</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ditto</td>\n      <td>pubmed</td>\n      <td>115.0</td>\n      <td>0.51</td>\n      <td>3.28 M</td>\n      <td>45.7 G</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ditto</td>\n      <td>sst2</td>\n      <td>45.0</td>\n      <td>137.34</td>\n      <td>0.66 M</td>\n      <td>1650.0 G</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>exact</td>\n      <td>femnist--s02</td>\n      <td>350.0</td>\n      <td>89.84</td>\n      <td>1.68 M</td>\n      <td>527.52 G</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>exact</td>\n      <td>pubmed</td>\n      <td>135.0</td>\n      <td>1.06</td>\n      <td>3.85 M</td>\n      <td>60.38 G</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>exact</td>\n      <td>sst2</td>\n      <td>60.0</td>\n      <td>34.34</td>\n      <td>0.88 M</td>\n      <td>873.33 G</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_runs.head(6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T13:46:52.835322Z",
     "end_time": "2023-04-19T13:46:52.917925Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
